{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "la1a8rUdI_Ps"
   },
   "source": [
    "# Building a Binary Classification Machine Learning Model To Predict Hospital Readmission in Patients with Diabetes\n",
    "\n",
    "<img src=\"https://s3.us-east-2.amazonaws.com/hidden.layers.assets/patient_graphic.png\" width=\"15%\" align=\"right\" margin-right=\"10px\"/>\n",
    "\n",
    "In this tutorial, we'll be looking at hospital admission data in patients with diabetes. This dataset was collected from 130 hospitals in the United States from 1999 to 2008. More details can be found on the UCI Machine Learning Repository [website](https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008).\n",
    "\n",
    "The goal is to build a binary classification model that preducts whether a patient with diabetes will be readmitted to the hopsital. We will be using a variety of open-source Python tools including pandas, numpy, matplotlib, scikit-learn, seaborn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jNM_69CVhYNn"
   },
   "source": [
    "### Step 1: Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VY2r-0i3DtbR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Zoi8LPvhfJo"
   },
   "source": [
    "### Step 2: Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rO23GyQIEjlJ"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://s3.us-east-2.amazonaws.com/explore.datasets/diabetes/patient_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZsmfxUmirf5"
   },
   "source": [
    "Let's take a peek at the first 5 rows of our newly created dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sc1CUJX6IXF1"
   },
   "outputs": [],
   "source": [
    "data.___()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e6jfVrUgi0AZ"
   },
   "source": [
    "What if we wanted to randomly sample rows from our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRr2X1XWi8Cw"
   },
   "outputs": [],
   "source": [
    "data._____(n=__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZ76H_-lhkUy"
   },
   "source": [
    "How big is the dataset? How many rows and columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FDEWkQmYIhyT"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbvujXXqjIkI"
   },
   "outputs": [],
   "source": [
    "print(f\"There are {data.shape[0]} rows (# admissions) and {data.shape[1]} columns (# features).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZRZcth4jcaL"
   },
   "source": [
    "What kind of features are we dealing with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zr1crRWnIjEl"
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o3U5eU65JUZn"
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_FIYup5k8QK"
   },
   "source": [
    "For your own reference, here's what each pandas datatype means:\n",
    "\n",
    "|column dtype|description|\n",
    "|------------|-----------|\n",
    "|int64|integer (e.g., 2)|\n",
    "|float64|floating point number (e.g., 2.0)|\n",
    "|object|string or mixed type|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tNZAkQK-UcRt"
   },
   "source": [
    "Looking at the columns, we can see that a large proportion are medication names. Let’s store these column names as a separate list, which we’ll get back to in a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "reV4mjZLUdg1"
   },
   "outputs": [],
   "source": [
    "medications = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
    "    'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone',\n",
    "    'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide',\n",
    "    'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
    "    'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone']\n",
    "\n",
    "print(f\"There are {len(medications)} medications represented as columns in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dtNWXvQ_Ufh3"
   },
   "source": [
    "### How many hospital admissions and unique patients are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9PEP3_jBUmQ8"
   },
   "outputs": [],
   "source": [
    "n_admissions = data['encounter_id'] .nunique()\n",
    "\n",
    "n_patients = data['patient_nbr'].nunique()\n",
    "\n",
    "print(f\"Number of hospital admissions: {n_admissions:,}\")\n",
    "print(f\"Number of unique patients: {n_patients:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YyLpXafKUuKs"
   },
   "source": [
    "### How many patients have had more than one hospital admission?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kc8fTkVhUwBN"
   },
   "outputs": [],
   "source": [
    "admissions_per_patient = data[ .    ].value_counts().reset_index()\n",
    "admissions_per_patient.columns = ['patient_nbr', 'count']\n",
    "\n",
    "multiple_admissions = admissions_per_patient[admissions_per_patient['count']>___]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kck2ptyfVIrf"
   },
   "outputs": [],
   "source": [
    "print(f\"Proportion of patients that have multiple admissions: {}\")\n",
    "print(f\"Maximum number of admissions for a given patient: {}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Ia6wPpOscLJ"
   },
   "source": [
    "### Step 3: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-iXuekR78B_"
   },
   "source": [
    "#### Decoding Admission Type\n",
    "\n",
    "The `admission_type_id` column describes the type of admission and is represented by integers. The `id` column links to descriptors found in a separate file. We'll update this column so that it represents the descriptor name instead of simply the id number.\n",
    "\n",
    "Our mapper files are located in `data/id_mappers/`. They are also stored on the cloud in a AWS S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "nyuLKdow793L",
    "outputId": "d22d88b3-07a8-4442-c2f6-2bc7d998e084"
   },
   "outputs": [],
   "source": [
    "admission_type = pd.read_csv(\"https://s3.us-east-2.amazonaws.com/explore.datasets/diabetes/id_mappers/admission_type_id.csv\")\n",
    "admission_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3-FfiFUy8DHX"
   },
   "source": [
    "We can see that the admission type mapper file has 3 values which represent missing data:\n",
    "\n",
    "1. NaN\n",
    "2. 'Not Mapped'\n",
    "3. 'Not Available'\n",
    "\n",
    "Let's collapse these into one category that represents a missing value. We can use `pandas` [replace](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.replace.html) method to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "geZO47-58Ejx"
   },
   "outputs": [],
   "source": [
    "missing_values = ['nan', 'Not Available', 'Not Mapped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VuF23Kov8QVy"
   },
   "outputs": [],
   "source": [
    "admission_type['description'] = admission_type['description'].replace(missing_values, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ufOCC7nz8oUe"
   },
   "source": [
    "After consolidating our missing values, let's take a look at all unique admission type descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aGJqonmZ8V-D"
   },
   "outputs": [],
   "source": [
    "admission_type['description'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e9R7ifmg9LcI"
   },
   "source": [
    "Great! We can now merge admission type into our original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLaNhD-w9S5M"
   },
   "outputs": [],
   "source": [
    "# renaming \"description\" column to \"admission_type\"\n",
    "admission_type.columns = ['admission_type_id', 'admission_type']\n",
    "\n",
    "# merging on \"admission_type_id\" (doing an inner join)\n",
    "data = data.merge(admission_type, on='admission_type_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d0DSPgh3-WK5"
   },
   "source": [
    "What are the most common types of admission?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xt8ApdLcAu2Y"
   },
   "outputs": [],
   "source": [
    "data['admission_type'].value_counts()\n",
    "\n",
    "# you can try out value_counts()\n",
    "# or plot using seaborn\n",
    "# sns.countplot(#define parameters inside)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWB9GR4dBNb3"
   },
   "source": [
    "#### Decoding Discharge Type\n",
    "\n",
    "In medicine, \"expired\" is a term that describes a patient who has died. We only want to predict hospital readmission for living patients so we're going to remove hospital admissions in which the patient was recorded as \"expired\" upon being discharged in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSI5jbJXTaUI"
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rN3xtVasBVZT"
   },
   "outputs": [],
   "source": [
    "discharge_disposition = pd.read_csv(\"https://s3.us-east-2.amazonaws.com/explore.datasets/diabetes/id_mappers/discharge_disposition_id.csv\")\n",
    "discharge_disposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2uQy8hLPBbYt"
   },
   "source": [
    "We'll first convert our `description` column to lowercase (`str.lower()`), then we'll search for rows that contain \"expired\" (`str.contains(\"expired\")`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AupKoYjBdQj"
   },
   "outputs": [],
   "source": [
    "discharge_disposition['expired'] = discharge_disposition['description'].str. ##### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fqU5ENhlBj4m"
   },
   "source": [
    "Now let's take a look at all discharge dispositions that indicate an expired patient. We'll create a new dataframe that filters for rows in which the expired column is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "gH0JaslpBkbA",
    "outputId": "5f6ce635-32fe-4e27-e9c7-073b9bc04b60"
   },
   "outputs": [],
   "source": [
    "discharge_expired = discharge_disposition[discharge_disposition['expired']== #### ]\n",
    "discharge_expired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-tsFHpcoBsba"
   },
   "outputs": [],
   "source": [
    "expired_ids = discharge_expired['discharge_disposition_id'].tolist()\n",
    "expired_ids\n",
    "# print(f\"discharge_disposition_id's that indicate an expired patient: {expired_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NlIREnRBBx6Z"
   },
   "source": [
    "The next step is to remove all rows in our original dataset that has `discharge_disposition_id` equal to one of the values in our `expired_ids` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ab81g6vRByi_"
   },
   "outputs": [],
   "source": [
    "data = data[~data[_____].isin(_______)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HxFjXiARCFKA"
   },
   "source": [
    "Note the tilde (~) - means \"bitwise not\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0qMsXn_mCeza"
   },
   "source": [
    "After removing expired patients, how many patients do we have in our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s8xfebr6CG25"
   },
   "outputs": [],
   "source": [
    "n_patients_nonexpired = data['patient_nbr'].nunique()\n",
    "print(f\"Original number of patients: {n_patients:,}\")\n",
    "print(f\"Number of expired patients: {n_patients-n_patients_nonexpired:,}\")\n",
    "print(f\"After filtering out expired patients: {n_patients_nonexpired:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8mEoyRoCqQ5"
   },
   "source": [
    "#### Converting Medication Features From Categorical to Boolean\n",
    "\n",
    "In our dataset, there are 24 columns that represent different types of medications. We're going to convert these medication columns into boolean variables. In Step 2, we created a list of medications. Let's see what a medication column looks like in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C92UoFCSJ2Zm"
   },
   "outputs": [],
   "source": [
    "medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "27x0v28oDiWa",
    "outputId": "3d709ae1-7540-4bf9-d1de-637fe9106808"
   },
   "outputs": [],
   "source": [
    "data[medications[0]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JQyi0SjyDpt4"
   },
   "source": [
    "Medication columns are currently categorical datatypes that have several possible categories including:\n",
    "\n",
    "- \"No\" (not taking the medication)\n",
    "- \"Up\" (increased medication dose)\n",
    "- \"Down\" (decrease medication dose)\n",
    "- \"Steady\" (no changes in dose)\n",
    "\n",
    "To keep things simple, we'll update the column to \"0\" (not taking the medication) to \"1\" (taking the medication). We're losing out on information regarding their dose change, but it's a compromise we're willing to make in order to simplify our dataset.\n",
    "\n",
    "We can use [numpy.where](https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html) to convert all instances of \"No\" to `0` and everything else (i.e., \"Up\", \"Down\", \"Steady\") to `1`. Let's loop through all medications and convert each column to boolean. We'll also drop our original medication column since we won't be needing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rSVCEnLyDsuC"
   },
   "outputs": [],
   "source": [
    "for m in medications:\n",
    "  data[f'{m}_bool'] = ######\n",
    "  data = data.drop(columns=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "epsGOtB4D6SU"
   },
   "source": [
    "Our medication data are now represented as boolean features. Let's take a look at the prevelance of these medications. We'll calcualte the proportion of patients taking each type of medication. Because some patients have had multiple hospital admissions in this dataset, we'll need to do some wrangling to determine whether a patient was on a given medication during any of their admissions. The wrangling process consists of the following steps:\n",
    "\n",
    "- applying `groupby` to `patient_nbr` and calculate the sum of admissions in which the patient was administered a medication\n",
    "- convert the column to boolean such that patients that have \"0\" are False and \"1\" is True\n",
    "- calculate the sum of patients on that specific medication\n",
    "- calculate the proportion of patients who were administered that medication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gddr6ygpD56H"
   },
   "outputs": [],
   "source": [
    "prevalence = []\n",
    "\n",
    "for m in medications:\n",
    "    patient_meds = data.groupby('patient_nbr')[f'{m}_bool'].sum().reset_index()\n",
    "    patient_meds[f'{m}_bool'] = patient_meds[f'{m}_bool'].astype(bool)\n",
    "    n_patients_on_med = patient_meds[f'{m}_bool'].sum()\n",
    "    proportion = n_patients_on_med/n_patients\n",
    "    prevalence.append(proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rO1WN8NSEK9s"
   },
   "source": [
    "Now that we have a list of medication prevelance, we can create a dataframe and sort by prevelance to determine which medications are most prevalent in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gW5nmWXyD52M"
   },
   "outputs": [],
   "source": [
    "# create dataframe with medication and prevalence columns\n",
    "medication_counts = pd.DataFrame({'medications':_____, 'prevalence': ____}) #### create dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ycn4rWA1EZCa"
   },
   "source": [
    "Let's visualize the top 10 most prevelant medications. We can use seaborn's [barplot](https://seaborn.pydata.org/generated/seaborn.barplot.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWFPyOz9EYJ5"
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=medication_counts.head(10), x='medications', y='prevalence', palette='viridis')\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdkjRranEw5j"
   },
   "source": [
    "If you're not a medical doctor, it might be difficult to interpret what these medications mean. \n",
    "\n",
    "[MeSH](https://en.wikipedia.org/wiki/Medical_Subject_Headings) (or Medical Subject Headings) are a type of \"tag\" that describes a medical term. We'll use [RxNav's API](https://rxnav.nlm.nih.gov/RxNormAPIs.html#) to further investigate which MeSH terms are assocaited with our list of medications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtWZRIh-FW-P"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def get_mesh_from_drug_name(drug_name):\n",
    "    drug_name = drug_name.strip()\n",
    "    rxclass_list = []\n",
    "    try:\n",
    "        r = requests.get(f\"https://rxnav.nlm.nih.gov/REST/rxclass/class/byDrugName.json?drugName={drug_name}&relaSource=MESH\")\n",
    "        response = r.json()\n",
    "        all_concepts = response['rxclassDrugInfoList']['rxclassDrugInfo']\n",
    "        for i in all_concepts:\n",
    "            rxclass_list.append(i['rxclassMinConceptItem']['className'])\n",
    "    except:\n",
    "        pass\n",
    "    return list(set(rxclass_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fTya-0p3FY2p"
   },
   "outputs": [],
   "source": [
    "# get MeSH terms for each medication \n",
    "mesh_med_descriptions = dict()\n",
    "for m in medications:\n",
    "    mesh_med_descriptions[m] = get_mesh_from_drug_name(  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NTQSzKl8Zkfo"
   },
   "outputs": [],
   "source": [
    "mesh_med_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7WEBheMIGcq7"
   },
   "source": [
    "#### Creating our Target Variable\n",
    "\n",
    "The goal of our model will be to predict whether a patient will get readmitted to the hospital. Looking at the `readmitted` column, we see that there are 3 possible values: \n",
    "\n",
    "1. `NO` (not readmitted)\n",
    "2. `>30` (readmitted more than 30 days after being discharged)\n",
    "3. `<30` (readmitted within 30 days of being discharged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwvaK_ZSGats"
   },
   "outputs": [],
   "source": [
    "data['readmitted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_lE8kA6Ghtd"
   },
   "source": [
    "Let's convert `readmitted` into a boolean column such that \"NO\" is 0 (not readmitted) and everything is 1 (did get readmitted). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZbD0db_TGpuK"
   },
   "outputs": [],
   "source": [
    "data['readmitted_bool'] = #### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMsb6t3dGvFH"
   },
   "source": [
    "## Step 4: Data Exploration and Visualization\n",
    "\n",
    "#### Assessing Missing Values\n",
    "\n",
    "To get a better sense of the missing values in our data, let's visualize it using [missingno](https://github.com/ResidentMario/missingno)'s \"nullity\" matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_iDwnslGyre"
   },
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "43pS45wPG5F_"
   },
   "source": [
    "### Patient Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "lomHZjUvG4YW",
    "outputId": "ce4db77c-b1ef-4858-a721-a5041d1d321b"
   },
   "outputs": [],
   "source": [
    "# let's plot age and gender\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x= ____ , data=data, palette='viridis')\n",
    "plt.title('Distribution of Age')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x=____, data=data, palette='viridis')\n",
    "plt.title('Distribution of Gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ou8iRudQG_ue"
   },
   "source": [
    "### What's the distribution of hospital stay length? How long was a stay on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "id": "soLXOzONHE7C",
    "outputId": "1a63642c-0ac1-4903-dfdf-ad6b84b79e3f"
   },
   "outputs": [],
   "source": [
    "# time_in_hospital\n",
    "sns.countplot(data[______ ], palette='viridis')\n",
    "plt.title('Length of Hospital Stay')\n",
    "print(f\"Mean length of hospital stay: {data['time_in_hospital']._____()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vcsttg9AHT-w"
   },
   "source": [
    "### How many medications were patients prescribed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q1gCy4rFHYD_"
   },
   "outputs": [],
   "source": [
    "# num_medications\n",
    "# max number of medications\n",
    "# average number of medications\n",
    "\n",
    "# try using sns.kdeplot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-1Qu1fmhihYU"
   },
   "outputs": [],
   "source": [
    "print(f\"Mean number of medications administered: {data['num_medications'].____()}\")\n",
    "print(f\"Max number of medications administered: {data['num_medications'].____()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bynzBNmNHar3"
   },
   "source": [
    "### How many previous inpatient visits? Emergency Room visits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6297h7SzHbpX"
   },
   "outputs": [],
   "source": [
    "# code here\n",
    "\n",
    "# number_inpatient\n",
    "# number_emergency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1S-Oui-1INfS"
   },
   "source": [
    "### Do patients have normal A1C levels?\n",
    "\n",
    "The A1C blood test is used to diagnose whether a patient has type I or II diabetes, and represents the average levels of blood sugar over the past 3 months. The higher the A1C level, the poorer a patient's blood sugar control which indicates a higher risk of diabetes complications. The table below represents Mayo Clinic's [guideline](https://www.mayoclinic.org/tests-procedures/a1c-test/about/pac-20384643) of how to interpret A1C levels:\n",
    "\n",
    "|interpretation|A1C level|\n",
    "|-----------|--------|\n",
    "|no diabetes|<5.7|\n",
    "|pre-diabetes|5.7-6.4|\n",
    "|diabetes|>6.5|\n",
    "|well-managed diabetes|<7|\n",
    "|poorly managed diabetes|>8|\n",
    "\n",
    "Our dataset has a `A1Cresult` which reflects a patient's A1C level during their hospital stay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLG1-b48HlSl"
   },
   "outputs": [],
   "source": [
    "data['A1Cresult'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p44Es-wqIdMQ"
   },
   "source": [
    "## Step 5: Feature Selection and Engineering\n",
    "\n",
    "Our dataset contains quite a few categorical variables. In general, machine learning models can't handle categorical variables so we will need to apply one-hot encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jVZP45WTJE20"
   },
   "source": [
    "### One-hot Encoding\n",
    "\n",
    "Let's say we want to convert a patient’s race to a numerical feature. We could use label encoding to convert each race to values 0-5 but this suggests an inherent order among races that does not exist. With one-hot encoding, each race becomes an independent feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zoz2YzMgIdCQ"
   },
   "outputs": [],
   "source": [
    "categorical = ['race', 'admission_type']\n",
    "\n",
    "for c in categorical:\n",
    "    data = pd.concat([data, pd.get_dummies(data[c], prefix=c)], axis= ___ ) # axis of 0 concats row-wise, 1 column-wise\n",
    "    data.drop(columns=c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhfH6FbeJee_"
   },
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qeauv9SBJgq1"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "data['age_label'] = label_encoder.fit_transform(data[' '])\n",
    "data['gender_bool'] = label_encoder.fit_transform(data[' '].astype(str))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHusY_-XJwp-"
   },
   "source": [
    "## Step 6: Defining the X and y Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Lgyyt0VJzDr"
   },
   "outputs": [],
   "source": [
    "med_features = ['metformin_bool', 'repaglinide_bool',\n",
    "    'nateglinide_bool', 'chlorpropamide_bool', 'glimepiride_bool',\n",
    "    'acetohexamide_bool', 'glipizide_bool', 'glyburide_bool',\n",
    "    'tolbutamide_bool', 'pioglitazone_bool', 'rosiglitazone_bool',\n",
    "    'acarbose_bool', 'miglitol_bool', 'troglitazone_bool',\n",
    "    'tolazamide_bool', 'examide_bool', 'citoglipton_bool', 'insulin_bool',\n",
    "    'glyburide-metformin_bool', 'glipizide-metformin_bool',\n",
    "    'glimepiride-pioglitazone_bool', 'metformin-rosiglitazone_bool',\n",
    "    'metformin-pioglitazone_bool']\n",
    "\n",
    "demographic_features = ['race_AfricanAmerican', 'race_Asian',\n",
    "    'race_Caucasian', 'race_Hispanic', 'race_Other', 'age_label',\n",
    "    'admission_type_Elective', 'admission_type_Newborn',\n",
    "    'admission_type_Trauma Center', 'admission_type_Urgent', 'gender_bool']\n",
    "\n",
    "other_features = ['num_lab_procedures', 'num_procedures',\n",
    "       'num_medications', 'number_outpatient', 'number_emergency',\n",
    "       'number_inpatient', 'number_diagnoses']\n",
    "\n",
    "all_features = med_features + demographic_features + other_features\n",
    "\n",
    "X = data[all_features]\n",
    "\n",
    "y = data['readmitted_bool']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDOL4PnRJ42v"
   },
   "source": [
    "## Step 7: Choosing our Binary Classification Model\n",
    "\n",
    "When building a binary classification model, there are a wide selection of machine learning models to choose from:\n",
    "\n",
    "- Random Forest Classification\n",
    "- Logistic Regression\n",
    "- Linear Discriminant Analysis\n",
    "- Support Vector Machines (SVM)\n",
    "- Gaussian Naive Bayes\n",
    "- k-Nearest Neighbours\n",
    "\n",
    "We’ll test out the Random Forest Classifier (RFC) for this dataset. RFC is an ensemble learning technique that works by creating a “forest” of decision trees. Each tree evaluates the data for a given patient and outputs a 0 or 1. Random Forest looks at the output of all trees and gives the majority vote as its result. Let’s say we have a forest with 3 trees and 2 of them predict the patient will be readmitted. The majority vote is that the patient will be readmitted.\n",
    "<img src=\"https://s3.us-east-2.amazonaws.com/hidden.layers.assets/random_forest.png\"/>\n",
    "\n",
    "We’re choosing Random Forest because:\n",
    "- it is robust to outliers\n",
    "- it is able to handle unbalanced datasets\n",
    "- it measures feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OX2Uo6WCJ7tk"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RandomForestClassifier().get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3iGBlsczKgZS"
   },
   "source": [
    "## Step 8: Hyperparameter Tuning\n",
    "\n",
    "Hyperparemter tuning is a critical step in the machine learning pipeline. It describes the process of choosing a set of optimal hyperparameters for a model. The hyperparameters that you select can have a significant impact on your model's performance. \n",
    "\n",
    "We're going to be testing out two hyperparameter tuning techniques offered by scikit-learn:\n",
    "\n",
    "- [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "- [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "\n",
    "<img src=\"https://s3.us-east-2.amazonaws.com/hidden.layers.assets/grid_search.png\" align=\"right\" width=\"20%\"/>\n",
    "\n",
    "With grid search, you define your search space as a grid of values and iterate over each grid point until you find the optimal combination of values. Let's say we want to tune `max_depth` and `n_estimators` in our RandomForestClassifer. We'll set our search space as follows:\n",
    "\n",
    "- n_estimators = [5,10,50]\n",
    "- max_depth = [3,5,10]\n",
    "\n",
    "This means that we'll have to train our model 9 times to test for every configuration of values. We'll choose the combination of n_estimators and max_depth that give us the best model performance.\n",
    "\n",
    "Let's implement this with scikit-learn's GridSearchCV. We first need to define our search space as a dictionary. We also need to initialize our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WXCsjpcKlsC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define search space \n",
    "search_space = {\n",
    "    'n_estimators': \n",
    "    'max_depth': \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u5F_2hBFLLfO"
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(rfc, search_space, cv=3)\n",
    "grid_search.fit(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yG4jZg_QLXdV"
   },
   "source": [
    "What are our optimal hyperparmaters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UPw3JvVfLZHP"
   },
   "outputs": [],
   "source": [
    "print(f\"Optimal hyperparameters: {grid_search._____}\")\n",
    "print(f\"Best score: {grid_search.____}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGHnyUtgaZ2k"
   },
   "source": [
    "Here, our score uses RFC's default metric, [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.score). If we want to optimize our model using another metric, we can specify `scoring = 'precision'` (or whichever metric we're interested in) inside GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rx6S_-liLhVq"
   },
   "source": [
    "We can also see a thorough report of our results with `cv_results_`. It shows fit time, score time, and mean train/test score (averaged over all folds). We'll sort by `mean_test_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbRyJEdTLh4g"
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AdfnjjrQLnEg"
   },
   "source": [
    "In 2012, Bergstra and Bengio from the University of Montreal proposed a new technique called [random search](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf) which is similar to grid search but instead of sampling over a discrete set of values, you’re now randomly sampling from a distribution of values. Random search is effective in situations where not all hyperparameters are equally important.\n",
    "\n",
    "<img src=\"https://s3.us-east-2.amazonaws.com/hidden.layers.assets/random_grid_search.png\" width=\"50%\"/>\n",
    "\n",
    "The visualization above gives an example of when random search can perform better. With grid search, you’re only looking at 3 different values of a given hyperparamter. But with random search you’re looking at nine different values. As you increase the number of samples in your random search, you increase the probability of finding the optimal hyperparameters for your model. \n",
    "\n",
    "Let's test out random search using scikit-learn's RandomizedSearchCV. We'll define our search space over a uniform distribution of values. We'll iterate 9 times, just like we did for grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "oXyuBusDLne4",
    "outputId": "be9165b3-b751-4100-f9ee-a0dba4471816"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# define search space\n",
    "search_space = {\n",
    "    'n_estimators': randint(5,20),\n",
    "    'max_depth': randint(4,15)\n",
    "}\n",
    "\n",
    "# define random search object and set n_iter to be 9\n",
    "random_search = RandomizedSearchCV(rfc, search_space, cv=__, n_iter=___)\n",
    "\n",
    "random_search.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DpTc3C4ILw6s"
   },
   "outputs": [],
   "source": [
    "print(f\"Optimal hyperparamters: {random_search.____}\")\n",
    "print(f\"Best score: {random_search.____}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fR3Min9ot20t"
   },
   "outputs": [],
   "source": [
    "# visualize cv results\n",
    "pd.DataFrame(random_search.cv_results_).sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mynLNRH5mTpF"
   },
   "source": [
    "Grid Search and Random Search are uninformed methods. If you're working with a very large search space, it might be a good idea to use a \"smarter\" approach such as [Sequential-Based Model Optimization](https://www.cs.ubc.ca/~hutter/papers/10-TR-SMAC.pdf). \n",
    "\n",
    "The SMBO approach keeps track of previous iteration results which is used to sample hyperapramters at the current iteration. In other words, SMBO is trying to reduce the number of iterations by sampling the most promising hyperparameters based on past results. You can check out [scikit-optimize](https://scikit-optimize.github.io/) to learn more about how to implement SMBO hyperparameter tuning with scikit-learn models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YeosEi-YL3Qu"
   },
   "source": [
    "## Step 9: Evaluating Model Performance\n",
    "\n",
    "There are several metrics that we can use to evaluate model performance:\n",
    "\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- F1-score\n",
    "\n",
    "We'll focus on accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "nUG1ZAdpL5dr",
    "outputId": "b00adced-25ba-4443-e311-ccbf5fc2280f"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split()\n",
    "\n",
    "# initialize model with best_params from Random Search or Grid Search\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# fit model with X_train and y_train\n",
    "rfc.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G2kfSZUru-nR",
    "outputId": "8d0071dd-20f3-4777-e87c-a55268504ca0"
   },
   "outputs": [],
   "source": [
    "# evaluate model with X_test and y_test\n",
    "rfc.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UD3nhqlXTZwk"
   },
   "source": [
    "### Precision and Recall\n",
    "\n",
    "Precision and recall are information retrieval metrics that evaluate classification models.\n",
    "\n",
    "- Precision: “What proportion of predicted readmitted patients were actually readmitted?”\n",
    "- Recall: “What proportion of readmitted patients were identified correctly?”\n",
    "\n",
    "<img src=\"https://s3.us-east-2.amazonaws.com/hidden.layers.assets/precision_recall.png\" width=\"70%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAg_n6ZZTLe5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "\n",
    "y_pred =  \n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCdxFjAhUKIH"
   },
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "Another way to assess our model’s performance is to visualize our results with a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uwAwMFZsUPHP"
   },
   "outputs": [],
   "source": [
    "labels = np.array([['TN','FP'],['FN','TP']])\n",
    "\n",
    "confusion = ### confusion_matrix\n",
    "sns.heatmap(confusion, annot=labels, fmt='', linewidths=2, cmap=\"Blues\")\n",
    "plt.xlabel(\"predicted\")\n",
    "plt.ylabel(\"actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lk0Et3D4MG7K"
   },
   "source": [
    "## Step 10: Examining Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IGt04NiXMIym"
   },
   "outputs": [],
   "source": [
    "# code here\n",
    "feature_importances = {\n",
    "    'features': ### list of column names \n",
    "    'importances': ### list of rfc feature_importances\n",
    "}\n",
    "\n",
    "important_features = pd.DataFrame(feature_importances)\n",
    "important_features.sort_values(by='importances', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "diabetes_dataset_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
