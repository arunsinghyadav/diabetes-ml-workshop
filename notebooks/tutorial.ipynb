{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Binary Classification Machine Learning Model To Predict Hospital Readmission in Patients with Diabetes\n",
    "\n",
    "In this tutorial, we'll be looking at hospital admission data in patients with diabetes. This dataset was collected from 130 hospitals in the United States from 1999 to 2008. More details can be found on the UCI Machine Learning Repository [website](https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008).\n",
    "\n",
    "This notebook is incomplete. You'll need to fill in the blanks in order for the cells to run successfully. To avoid setting up an environment locally, you can run this noteobok in the cloud using Google Colab. See Colab notebook [here](https://colab.research.google.com/drive/1LBth_Yk2jAyegg-elx9P7ljrYhojhe0z)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing Depedencies\n",
    "\n",
    "Before getting started, we'll need to import several packages. These include:\n",
    "\n",
    "- [pandas](https://pandas.pydata.org/pandas-docs/stable/) - a package for performing data analysis and manipulation\n",
    "- [matplotlib](https://matplotlib.org/) - the standard Python plotting package\n",
    "- [seaborn](https://seaborn.pydata.org/) - a dataframe-centric visualization package that is built off of **matplotlib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Data\n",
    "\n",
    "We will be loading in the data as a pandas DataFrame.\n",
    "\n",
    "The data is stored in a csv file. We'll import this data using a pandas method called `read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/patient_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a glimpse of our data, we can use either the `head()`, which shows the first 5 rows, or `sample()` which randomly samples rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.___() # look at first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(n= __) # set n to equal the number of rows you want to sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many rows and columns are in our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.____ # get shape of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {} columns (features) and {} rows (hospital admissions).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does each row represent a unique patient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patients = data['   '].nunique()\n",
    "n_admissions = data['   '].nunique()\n",
    "\n",
    "\n",
    "print(f\"There are {n_patients} patients in this dataset.\")\n",
    "print(f\"There are {n_admissions} hospital admissions in this dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Cleaning \n",
    "\n",
    "There are 3 columns in our dataset which represent ID's that link to descriptors in separate files: \n",
    "\n",
    "1. `admission_type_id`\n",
    "2. `admission_source_id`\n",
    "3. `discharge_disposition_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['admission_type_id', 'admission_source_id', 'discharge_disposition_id']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll update these 3 columns so that they represent the descriptor name instead of simply the id number.\n",
    "\n",
    "Our mapper files are located in `data/id_mappers/` as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('data/id_mappers/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Decoding  `admission_type_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_type = pd.read_csv(\"data/id_mappers/admission_type_id.csv\")\n",
    "admission_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the admission type mapper file has 3 values which represent missing data:\n",
    "\n",
    "1. NaN\n",
    "2. 'Not Mapped'\n",
    "3. 'Not Available'\n",
    "\n",
    "Let's collapse these into one category that represents a missing value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = {'nan': None, 'Not Available': None, 'Not Mapped': None}\n",
    "admission_type['description'] = admission_type['description'].replace(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_type_mapper = admission_type.to_dict()['description']\n",
    "admission_type_mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a \"clean\" mapper, we can apply it to our dataset. We can use [pandas.Series.map](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html) to map `admission_type_id` values in our original dataframe to the descriptors in our `admission_type_mapper` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['admission_type'] = data['admission_type_id'].map(admission_type_mapper)\n",
    "data[['admission_type']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Decoding  `admission_source_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_source = pd.read_csv(\"data/id_mappers/admission_source_id.csv\")\n",
    "admission_source.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are significantly more ID's represented in the `admission_source_id.csv` file as compared to `admission_type_id.csv`. Let's take a look at the list of all descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_source['description'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that there are 4 missing values:\n",
    "\n",
    "- 'Not Available' \n",
    "- 'Unknown/Invalid'\n",
    "- 'Not Mapped'\n",
    "- 'nan'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Decoding  `discharge_disposition_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_disposition = pd.read_csv(\"data/id_mappers/discharge_disposition_id.csv\")\n",
    "\n",
    "discharge_disposition['description'].tolist()\n",
    "# discharge_disposition['description'] = discharge_disposition['description'].replace({'Not Available': None, 'NaN': None, 'nan': None, 'Unknown/Invalid': None, 'Not Mapped': None})\n",
    "# discharge_disposition_mapper = discharge_disposition.to_dict()['description']\n",
    "\n",
    "# data['discharge_disposition'] = data['discharge_disposition_id'].map(discharge_disposition_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['admission_type_id', 'admission_source_id', 'discharge_disposition_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values Assessment\n",
    "\n",
    "To get a better sense of the missing values in our data, let's visualize it using [missingno](https://github.com/ResidentMario/missingno)'s \"nullity\" matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "msno.matrix(data)\n",
    "\n",
    "# other methods to check out:\n",
    "# - msno.bar\n",
    "# - msno.heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(data['age'], palette='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time in Hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(data['time_in_hospital'], palette='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Diagnoses, Procedures, Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['number_emergency', 'num_procedures', 'number_diagnoses', 'number_inpatient']\n",
    "plt.figure(figsize=(12,8))\n",
    "for i, f in enumerate(features):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    sns.countplot(data[f])\n",
    "    plt.title(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medical Specialty\n",
    "\n",
    "Medical specialty of attending physician."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['medical_specialty'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['diabetesMed'] = data['diabetesMed'].map({'Yes': 1, 'No':0})\n",
    "data['diabetesMed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['A1Cresult']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['A1Cresult'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readmitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['readmitted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['readmitted_bool'] = np.where(data['readmitted']=='NO', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gender'] = data['gender'].map({'Female': 0, 'Male':1})\n",
    "data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
